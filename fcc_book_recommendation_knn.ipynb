{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGd4NYQX1Rf_"
      },
      "source": [
        "*Note: You are currently reading this using Google Colaboratory which is a cloud-hosted version of Jupyter Notebook. This is a document containing both text cells for documentation and runnable code cells. If you are unfamiliar with Jupyter Notebook, watch this 3-minute introduction before starting this challenge: https://www.youtube.com/watch?v=inN8seMm7UI*\n",
        "\n",
        "---\n",
        "\n",
        "In this challenge, you will create a book recommendation algorithm using **K-Nearest Neighbors**.\n",
        "\n",
        "You will use the [Book-Crossings dataset](http://www2.informatik.uni-freiburg.de/~cziegler/BX/). This dataset contains 1.1 million ratings (scale of 1-10) of 270,000 books by 90,000 users. \n",
        "\n",
        "After importing and cleaning the data, use `NearestNeighbors` from `sklearn.neighbors` to develop a model that shows books that are similar to a given book. The Nearest Neighbors algorithm measures distance to determine the â€œclosenessâ€ of instances.\n",
        "\n",
        "Create a function named `get_recommends` that takes a book title (from the dataset) as an argument and returns a list of 5 similar books with their distances from the book argument.\n",
        "\n",
        "This code:\n",
        "\n",
        "`get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\")`\n",
        "\n",
        "should return:\n",
        "\n",
        "```\n",
        "[\n",
        "  'The Queen of the Damned (Vampire Chronicles (Paperback))',\n",
        "  [\n",
        "    ['Catch 22', 0.793983519077301], \n",
        "    ['The Witching Hour (Lives of the Mayfair Witches)', 0.7448656558990479], \n",
        "    ['Interview with the Vampire', 0.7345068454742432],\n",
        "    ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', 0.5376338362693787],\n",
        "    ['The Vampire Lestat (Vampire Chronicles, Book II)', 0.5178412199020386]\n",
        "  ]\n",
        "]\n",
        "```\n",
        "\n",
        "Notice that the data returned from `get_recommends()` is a list. The first element in the list is the book title passed in to the function. The second element in the list is a list of five more lists. Each of the five lists contains a recommended book and the distance from the recommended book to the book passed in to the function.\n",
        "\n",
        "If you graph the dataset (optional), you will notice that most books are not rated frequently. To ensure statistical significance, remove from the dataset users with less than 200 ratings and books with less than 100 ratings.\n",
        "\n",
        "The first three cells import libraries you may need and the data to use. The final cell is for testing. Write all your code in between those cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y1onB6kUvo4Z"
      },
      "outputs": [],
      "source": [
        "# import libraries (you may add additional imports but you may not have to)\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import requests\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', \n",
        "                      category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Downloading dataset\n",
        "r = requests.get('https://cdn.freecodecamp.org/project-data/books/book-crossings.zip') \n",
        "open('book-crossings.zip', 'wb').write(r.content)\n",
        "\n",
        "with zipfile.ZipFile('book-crossings.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_recommends(book, verbose=False):\n",
        "\n",
        "    # Storing dataset into Pandas Dataframes\n",
        "    books = pd.read_csv('BX-Books.csv', sep=';', error_bad_lines=False,\n",
        "                    warn_bad_lines=False, encoding=\"latin-1\", low_memory=False)\n",
        "    books.columns = ['ISBN', 'bookTitle', 'bookAuthor', 'yearOfPublication',\n",
        "                 'publisher', 'imageUrlS', 'imageUrlM', 'imageUrlL']\n",
        "    users = pd.read_csv('BX-Users.csv', sep=';', error_bad_lines=False,\n",
        "                    warn_bad_lines=False, encoding=\"latin-1\", low_memory=False)\n",
        "    users.columns = ['userID', 'Location', 'Age']\n",
        "    ratings = pd.read_csv('BX-Book-Ratings.csv', sep=';', error_bad_lines=False, \n",
        "                          warn_bad_lines=False, encoding=\"latin-1\", low_memory=False)\n",
        "    ratings.columns = ['userID', 'ISBN', 'bookRating']\n",
        "\n",
        "\n",
        "    # Removing users with less than 200 ratings and books with less than 100 ratings\n",
        "    counts_users = ratings['userID'].value_counts()\n",
        "    counts_books = ratings['ISBN'].value_counts()\n",
        "    counts_user_indices = ratings['userID'].isin(counts_users[counts_users >= 200].index)\n",
        "    counts_books_indices = ratings['ISBN'].isin(counts_books[counts_books >= 100].index)\n",
        "    combined_counts = counts_user_indices & counts_books_indices\n",
        "    ratings = ratings[combined_counts]\n",
        "    \n",
        "    # Combining ratings and books and removing unnecessary columns\n",
        "    combine_book_rating = pd.merge(ratings, books, on='ISBN')\n",
        "    columns = ['yearOfPublication', 'publisher',\n",
        "            'bookAuthor', 'imageUrlS', 'imageUrlM', 'imageUrlL']\n",
        "    combine_book_rating = combine_book_rating.drop(columns, axis=1)\n",
        "    \n",
        "    # Remove rows with no title\n",
        "    combine_book_rating = combine_book_rating.dropna(axis=0, subset=['bookTitle'])\n",
        "    \n",
        "    # Adding the total number of ratings and grouping per book\n",
        "    book_ratingCount = (combine_book_rating.\n",
        "                        groupby(by=['bookTitle'])['bookRating'].\n",
        "                        count().\n",
        "                        reset_index().\n",
        "                        rename(columns={'bookRating': 'totalRatingCount'})\n",
        "                        [['bookTitle', 'totalRatingCount']])\n",
        "    \n",
        "    # Merging the previous dataframe with the ratings+books dataframe\n",
        "    rating_with_totalRatingCount = combine_book_rating.merge(\n",
        "        book_ratingCount, left_on='bookTitle', right_on='bookTitle', how='left')\n",
        "    \n",
        "    # Removing duclicate ratings\n",
        "    rating_with_totalRatingCount = rating_with_totalRatingCount.drop_duplicates([\n",
        "                                                                                'userID', 'bookTitle'])\n",
        "    \n",
        "    # Reshaping rating_with_totalRatingCount to have book titles as indices, user IDs as columns and rating as values\n",
        "    rating_with_totalRatingCount_pivot_with_na = rating_with_totalRatingCount.pivot(\n",
        "        index='bookTitle', columns='userID', values='bookRating')\n",
        "    rating_with_totalRatingCount_pivot = rating_with_totalRatingCount_pivot_with_na.fillna(\n",
        "        0)\n",
        "\n",
        "    # Converting to sparse matrix for performance considerations\n",
        "    rating_with_totalRatingCount_matrix = csr_matrix(\n",
        "        rating_with_totalRatingCount_pivot.values)\n",
        "    \n",
        "    # Creating and fitting the model\n",
        "    model_knn = NearestNeighbors(n_neighbors=6, metric='cosine')\n",
        "    fitted_model = model_knn.fit(rating_with_totalRatingCount_matrix)\n",
        "\n",
        "    distances, indices = fitted_model.kneighbors(\n",
        "        rating_with_totalRatingCount_pivot.loc[book].values.reshape(1, -1))\n",
        "\n",
        "    book_list = []\n",
        "    for i in range(1, 6):\n",
        "       book_list.append([rating_with_totalRatingCount_pivot.index[indices.flatten()[i]], distances.flatten()[i]])\n",
        "       \n",
        "    book_list.reverse()\n",
        "    recommended_books = [book, book_list]\n",
        "    return recommended_books\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Use the cell below to test your function. The `test_book_recommendation()` function will inform you if you passed the challenge or need to keep trying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jd2SLCh8oxMh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\"Where the Heart Is (Oprah's Book Club (Paperback))\", [[\"I'll Be Seeing You\", 0.8016210581447822], ['The Weight of Water', 0.7708583572697412], ['The Surgeon', 0.7699410973804288], ['I Know This Much Is True', 0.7677075092617776], ['The Lovely Bones: A Novel', 0.7234864549790632]]]\n",
            "You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\n"
          ]
        }
      ],
      "source": [
        "books = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "print(books)\n",
        "\n",
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]\n",
        "  for i in range(2): \n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "fcc_book_recommendation_knn.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "915084977eb114fda143a7d765c9925b91d6b51baca5f51a21da94e92a16c86c"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
